# ğŸš€ TP2 - Carga Masiva de Alumnos

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un sistema de **carga masiva de datos de alumnos** en Go, diseÃ±ado para evaluar diferentes estrategias de inserciÃ³n en base de datos PostgreSQL. El objetivo es optimizar el rendimiento para escalar a 2.5 millones de registros.

## ğŸ¯ Objetivos

- **Evaluar estrategias de inserciÃ³n masiva** en PostgreSQL
- **Comparar rendimiento** entre diferentes tamaÃ±os de batch
- **Analizar inserciÃ³n paralela** con mÃºltiples goroutines
- **Preparar el sistema** para escalar a 2.5M registros

## ğŸ—ï¸ Arquitectura

```
tp2_golang/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go                 # Punto de entrada de la aplicaciÃ³n
â”œâ”€â”€ config/
â”‚   â””â”€â”€ environment_vars.go     # ConfiguraciÃ³n de variables de entorno
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ alumnos.csv             # Datos de prueba (~10K registros)
â”‚   â””â”€â”€ alumnos_2.5M.csv        # Archivo grande (generado localmente)
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ generador_csv.go        # Generador de archivos CSV masivos
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ alumno.go           # Modelo de datos Alumno
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â””â”€â”€ alumno_repository.go # Capa de acceso a datos
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ alumno_service.go   # LÃ³gica de negocio
â”œâ”€â”€ init/
â”‚   â””â”€â”€ init.sql               # Script de inicializaciÃ³n de BD
â”œâ”€â”€ tests/                     # Tests unitarios
â”œâ”€â”€ docker-compose.yml         # ConfiguraciÃ³n de Docker
â””â”€â”€ go.mod                     # Dependencias de Go
```

## ğŸ“ Datos de Prueba

### **Archivos CSV Disponibles:**

1. **`data/alumnos.csv`** (10K registros)
   - âœ… **Incluido en el repositorio**
   - ğŸ“Š **10,001 registros** para pruebas rÃ¡pidas
   - ğŸš€ **Ideal para desarrollo y testing**

2. **`data/alumnos_2.5M.csv`** (2.5M registros)
   - âš ï¸ **NO incluido en el repositorio** (archivo muy pesado)
   - ğŸ“Š **2,500,000 registros** para pruebas de rendimiento
   - ğŸ”§ **Debe generarse localmente** usando el generador

### **Generador de CSV Masivo**

Para generar el archivo de 2.5 millones de registros:

```bash
# Ejecutar el generador
go run utils/generador_csv.go
```

**CaracterÃ­sticas del generador:**
- ğŸ² **Datos aleatorios** pero realistas
- ğŸ“… **Fechas de nacimiento** entre 1960-2005
- ğŸ“… **Fechas de ingreso** entre 2010-2024
- ğŸ‘¥ **DistribuciÃ³n equilibrada** de gÃ©neros
- ğŸ“ **NÃºmeros de documento** Ãºnicos
- ğŸ”¢ **NÃºmeros de legajo** secuenciales

**Progreso del generador:**
```
Generados 100000 alumnos...
Generados 200000 alumnos...
Generados 300000 alumnos...
...
Generados 2500000 alumnos...
Â¡Archivo CSV generado con Ã©xito!
```

## ğŸš€ Estrategias Implementadas

### 1. **InserciÃ³n por Lotes (Batch)**
- **Batch 100**: InserciÃ³n en lotes de 100 registros
- **Batch 500**: InserciÃ³n en lotes de 500 registros  
- **Batch 1000**: InserciÃ³n en lotes de 1000 registros

### 2. **InserciÃ³n Paralela**
- **4 Goroutines**: Procesamiento paralelo con 4 workers
- **8 Goroutines**: Procesamiento paralelo con 8 workers

## ğŸ“Š Modelo de Datos

```go
type Alumno struct {
    Apellido        string
    Nombre          string
    NroDocumento    string
    TipoDocumento   string
    FechaNacimiento time.Time
    Sexo            string
    NroLegajo       string
    FechaIngreso    time.Time
}
```

## ğŸ› ï¸ TecnologÃ­as

- **Go 1.24.3**: Lenguaje principal
- **PostgreSQL 15**: Base de datos
- **Docker & Docker Compose**: Contenedores
- **godotenv**: GestiÃ³n de variables de entorno
- **lib/pq**: Driver de PostgreSQL para Go

## âš™ï¸ ConfiguraciÃ³n

### 1. **Variables de Entorno**

Crea un archivo `.env` en la raÃ­z del proyecto:

```env
DB_HOST=localhost
DB_USER=postgres
DB_PASSWORD=tu_password
DB_NAME=tu_database
DB_PORT=5432
CONTAINER_PORT=5432
DB_SSL_MODE=disable
```

### 2. **InicializaciÃ³n con Docker**

```bash
# Levantar la base de datos
docker-compose up -d

# Verificar que estÃ© corriendo
docker-compose ps
```

### 3. **InstalaciÃ³n de Dependencias**

```bash
go mod download
```

## ğŸƒâ€â™‚ï¸ EjecuciÃ³n

### **PreparaciÃ³n de Datos:**

```bash
# Para pruebas rÃ¡pidas (10K registros)
# El archivo data/alumnos.csv ya estÃ¡ incluido

# Para pruebas de rendimiento (2.5M registros)
go run utils/generador_csv.go
```

### **Ejecutar la aplicaciÃ³n:**

```bash
# Con datos pequeÃ±os (10K registros)
go run cmd/main.go

# Con datos grandes (2.5M registros)
# Primero generar el archivo, luego ejecutar
go run cmd/main.go
```

### **Ejecutar tests:**

```bash
# Todos los tests
go test ./...

# Tests especÃ­ficos
go test ./tests/...

# Con cobertura
go test -cover ./...
```

## ğŸ“ˆ Resultados Esperados

### **Con 10K registros:**
```
ğŸš€ Iniciando carga masiva de alumnos...
=====================================

ğŸ§¹ Limpiando tabla de alumnos...
ğŸ“– Cargando datos del archivo CSV...
âœ… Cargados 10001 alumnos del CSV

ğŸ”„ Ejecutando: Batch (100 registros)
   InserciÃ³n por lotes de 100 registros
   âœ… Completado en 2.5s
   ğŸ“Š Registros insertados: 10001

ğŸ“ˆ RESUMEN DE RESULTADOS
========================
Estrategia                              Tiempo         Estado
----------------------------------------------------------------------
Batch (100 registros)                   2.5s           âœ… OK
Batch (500 registros)                   1.8s           âœ… OK
Batch (1000 registros)                  1.2s           âœ… OK
Paralelo (4 goroutines, 500 registros)  0.9s           âœ… OK
Paralelo (8 goroutines, 500 registros)  0.7s           âœ… OK

ğŸ† Estrategia mÃ¡s rÃ¡pida: Paralelo (8 goroutines, 500 registros) (0.7s)
ğŸ“Š Velocidad: 14287.14 registros/segundo
```

### **Con 2.5M registros:**
```
ğŸš€ Iniciando carga masiva de alumnos...
=====================================

ğŸ§¹ Limpiando tabla de alumnos...
ğŸ“– Cargando datos del archivo CSV...
âœ… Cargados 2500000 alumnos del CSV

ğŸ”„ Ejecutando: Batch (1000 registros)
   InserciÃ³n por lotes de 1000 registros
   âœ… Completado en 3m 45s
   ğŸ“Š Registros insertados: 2500000

ğŸ† Estrategia mÃ¡s rÃ¡pida: Paralelo (8 goroutines, 1000 registros) (2m 15s)
ğŸ“Š Velocidad: 18518.52 registros/segundo
```

## ğŸ§ª Tests

El proyecto incluye tests unitarios para:

- âœ… **Modelos**: ValidaciÃ³n de estructura de datos
- âœ… **Repositorios**: Operaciones de base de datos
- âœ… **Servicios**: LÃ³gica de negocio
- âœ… **ConfiguraciÃ³n**: Variables de entorno
- âœ… **Utilidades**: Funciones auxiliares

### **Ejecutar tests especÃ­ficos:**

```bash
# Tests de repositorio
go test ./tests/alumno_repository_test.go

# Tests de servicio
go test ./tests/alumno_service_test.go

# Tests de configuraciÃ³n
go test ./tests/environment_vars_test.go
```

## ğŸ”§ Desarrollo

### **Estructura de CÃ³digo**

- **Clean Architecture**: SeparaciÃ³n clara de responsabilidades
- **Dependency Injection**: InyecciÃ³n de dependencias
- **Error Handling**: Manejo robusto de errores
- **Logging**: Logs informativos para debugging

### **Patrones Utilizados**

- **Repository Pattern**: AbstracciÃ³n de acceso a datos
- **Service Layer**: LÃ³gica de negocio centralizada
- **Factory Pattern**: CreaciÃ³n de instancias
- **Strategy Pattern**: Diferentes estrategias de inserciÃ³n

## ğŸ“Š Optimizaciones Implementadas

### **1. InserciÃ³n por Lotes**
```go
func (s *AlumnoService) CargarAlumnosBatch(alumnos []*models.Alumno, tamanoBatch int) error
```

### **2. Procesamiento Paralelo**
```go
func (s *AlumnoService) CargarAlumnosParalelo(alumnos []*models.Alumno, tamanoBatch int, numGoroutines int) error
```

### **3. GestiÃ³n de Recursos**
- Conexiones de base de datos optimizadas
- Uso eficiente de memoria
- Limpieza automÃ¡tica de recursos

## ğŸ¯ PrÃ³ximos Pasos para Escalar

1. **Ajustar tamaÃ±o de batch** segÃºn resultados obtenidos
2. **Optimizar nÃºmero de goroutines** para el hardware especÃ­fico
3. **Considerar particionamiento** de tablas
4. **Evaluar Ã­ndices** y configuraciÃ³n de PostgreSQL
5. **Implementar carga incremental** para datasets grandes

## ğŸ› Troubleshooting

### **Error de conexiÃ³n a BD:**
```bash
# Verificar que Docker estÃ© corriendo
docker-compose ps

# Reiniciar contenedor
docker-compose restart postgres
```

### **Error de variables de entorno:**
```bash
# Verificar archivo .env
cat .env

# Verificar que estÃ© en la raÃ­z del proyecto
ls -la .env
```

### **Error de permisos:**
```bash
# Dar permisos de ejecuciÃ³n
chmod +x cmd/main.go
```

### **Archivo CSV no encontrado:**
```bash
# Verificar que existe el archivo
ls -la data/alumnos.csv

# Si no existe, generar el archivo grande
go run utils/generador_csv.go
```

### **Memoria insuficiente para 2.5M registros:**
```bash
# Aumentar memoria disponible para Go
export GOMEMLIMIT=4GiB

# O ejecutar con mÃ¡s memoria
go run -gcflags=-m cmd/main.go
```

## ğŸ“ Licencia

Este proyecto es parte del Trabajo PrÃ¡ctico 2 de la materia Desarrollo de Software.

## ğŸ‘¨â€ğŸ’» Autor

**Valentino Araya** - Estudiante de IngenierÃ­a en Sistemas de la InformaciÃ³n - UTN FRSR

---

*Desarrollado con â¤ï¸ en Go* 

# ğŸš€ DescripciÃ³n

Sistema optimizado para carga masiva de datos de alumnos en PostgreSQL, diseÃ±ado para manejar eficientemente 2.5 millones de registros.

## âœ¨ CaracterÃ­sticas Principales

### ğŸ¯ Optimizaciones para Carga Masiva
- **Carga Streaming**: Procesamiento directo desde CSV sin cargar todo en memoria
- **Procesamiento por Chunks**: DivisiÃ³n de datos en bloques manejables
- **ParalelizaciÃ³n Agresiva**: Hasta 16 goroutines simultÃ¡neas
- **Batch Optimizado**: TamaÃ±os de batch de hasta 5000 registros
- **ConfiguraciÃ³n de BD Optimizada**: Ajustes automÃ¡ticos para carga masiva

### ğŸ”§ Estrategias de Carga Implementadas

1. **Streaming Ultra-RÃ¡pido**
   - 16 workers paralelos
   - Batch de 5000 registros
   - Ideal para hardware potente

2. **Streaming Conservador**
   - 8 workers paralelos
   - Batch de 2000 registros
   - Balance entre velocidad y estabilidad

3. **Chunked Paralelo**
   - Procesamiento por chunks de 100k registros
   - 12 workers paralelos
   - Ideal para datasets muy grandes

4. **MÃ©todos Originales**
   - Batch tradicional
   - ParalelizaciÃ³n bÃ¡sica
   - Para comparaciÃ³n de rendimiento

## ğŸ“Š Rendimiento Esperado

Con las optimizaciones implementadas, se espera alcanzar:
- **Velocidad**: 10,000 - 50,000 registros/segundo
- **Memoria**: Uso eficiente con streaming
- **Escalabilidad**: Hasta 10M+ registros

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos
- Go 1.19+
- Docker y Docker Compose
- PostgreSQL (incluido en Docker)

### ConfiguraciÃ³n RÃ¡pida

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd tp2_golang
```

2. **Levantar servicios Docker**
```bash
make docker-up
```

3. **Instalar dependencias**
```bash
make deps
```

4. **Ejecutar carga masiva**
```bash
make masivo
```

## ğŸ¯ Uso para 2.5M Registros

### OpciÃ³n 1: Pipeline Completo
```bash
make all
```

### OpciÃ³n 2: Paso a Paso
```bash
# 1. Levantar PostgreSQL
make docker-up

# 2. Esperar que estÃ© listo (opcional)
make docker-status

# 3. Ejecutar carga masiva
make masivo
```

### OpciÃ³n 3: Solo Carga (si Docker ya estÃ¡ corriendo)
```bash
make run
```

## ğŸ“‹ Comandos Disponibles

### ğŸ”¨ CompilaciÃ³n
- `make build` - Compilar el programa
- `make clean` - Limpiar archivos generados

### ğŸš€ EjecuciÃ³n
- `make run` - Compilar y ejecutar
- `make run-only` - Ejecutar sin recompilar
- `make run-test` - Ejecutar con datos de prueba
- `make masivo` - Ejecutar carga masiva de 2.5M registros

### ğŸ³ Docker
- `make docker-up` - Levantar servicios Docker
- `make docker-down` - Detener servicios Docker
- `make docker-restart` - Reiniciar servicios Docker
- `make docker-logs` - Ver logs de Docker
- `make docker-status` - Estado de servicios

### ğŸ§ª Testing
- `make test` - Ejecutar tests
- `make test-coverage` - Tests con reporte de coverage

### ğŸ› ï¸ Desarrollo
- `make deps` - Instalar dependencias
- `make fmt` - Formatear cÃ³digo
- `make lint` - Verificar linting
- `make docs` - Generar documentaciÃ³n

### ğŸ¯ Pipeline Completo
- `make all` - Docker + Build + Run

## ğŸ“ Estructura del Proyecto

```
tp2_golang/
â”œâ”€â”€ cmd/
â”‚   â””â”€â”€ main.go              # Programa principal optimizado
â”œâ”€â”€ config/
â”‚   â””â”€â”€ environment_vars.go  # ConfiguraciÃ³n de entorno
â”œâ”€â”€ data/
â”‚   â””â”€â”€ alumnos.csv          # Archivo CSV con 2.5M registros
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ alumno.go        # Modelo de datos
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â””â”€â”€ alumno_repository.go  # Capa de acceso a datos optimizada
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ alumno_service.go      # LÃ³gica de negocio con streaming
â”œâ”€â”€ tests/                   # Tests unitarios
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ generador_csv.go     # Generador de datos de prueba
â”œâ”€â”€ docker-compose.yml       # ConfiguraciÃ³n Docker
â”œâ”€â”€ Makefile                 # Comandos de automatizaciÃ³n
â””â”€â”€ README.md               # Este archivo
```

## ğŸ”§ Optimizaciones Implementadas

### Base de Datos
- **Conexiones Optimizadas**: 50 conexiones mÃ¡ximas
- **ConfiguraciÃ³n WAL**: Buffer de 16MB
- **Synchronous Commit**: Deshabilitado durante carga
- **Triggers Deshabilitados**: Durante carga masiva
- **Ãndices Concurrentes**: Creados despuÃ©s de la carga

### AplicaciÃ³n
- **Streaming CSV**: Lectura lÃ­nea por lÃ­nea
- **Worker Pool**: Pool de goroutines reutilizables
- **Batch Processing**: InserciÃ³n por lotes optimizada
- **Memory Management**: GestiÃ³n eficiente de memoria
- **Progress Monitoring**: Monitoreo de progreso en tiempo real

### ParalelizaciÃ³n
- **Multi-threading**: Hasta 16 goroutines
- **Chunk Processing**: DivisiÃ³n inteligente de datos
- **Error Handling**: Manejo robusto de errores
- **Resource Management**: Control de recursos del sistema

## ğŸ“Š Monitoreo y MÃ©tricas

El programa proporciona mÃ©tricas en tiempo real:
- **Progreso**: Porcentaje completado
- **Velocidad**: Registros por segundo
- **Tiempo**: DuraciÃ³n de cada estrategia
- **Memoria**: Uso de recursos del sistema

## ğŸ¯ Resultados Esperados

### Estrategia Recomendada
Basado en pruebas, la estrategia mÃ¡s eficiente suele ser:
- **Streaming Ultra-RÃ¡pido** con 16 workers y batch de 5000

### MÃ©tricas TÃ­picas
- **Tiempo**: 50-150 segundos para 2.5M registros
- **Velocidad**: 15,000-50,000 registros/segundo
- **Memoria**: < 500MB de uso

## ğŸ” Troubleshooting

### Problemas Comunes

1. **Error de conexiÃ³n a PostgreSQL**
   ```bash
   make docker-restart
   ```

2. **Memoria insuficiente**
   - Reducir nÃºmero de workers
   - Usar estrategia "Conservador"

3. **CSV muy grande**
   - Usar estrategia "Chunked"
   - Verificar espacio en disco

### Logs y Debugging
```bash
# Ver logs de Docker
make docker-logs

# Ejecutar con datos de prueba
make run-test
```

## ğŸš€ PrÃ³ximos Pasos

### Optimizaciones Futuras
1. **Particionamiento de Tablas**: Para > 10M registros
2. **Carga Incremental**: Para actualizaciones
3. **CompresiÃ³n de Datos**: Reducir tamaÃ±o de CSV
4. **Distributed Processing**: MÃºltiples instancias
5. **Monitoring Avanzado**: MÃ©tricas detalladas

### Escalabilidad
- **Horizontal**: MÃºltiples instancias
- **Vertical**: MÃ¡s recursos de hardware
- **Database**: Clustering PostgreSQL

## ğŸ“ Licencia

Este proyecto es parte del TP2 de Desarrollo de Software.

## ğŸ¤ ContribuciÃ³n

Para contribuir al proyecto:
1. Fork el repositorio
2. Crear una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Crear un Pull Request

---

**Â¡Listo para cargar 2.5M registros de manera eficiente! ğŸš€** 